{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b87f85-e35a-4f75-96a6-c669ac121347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0      842302         M        17.99         10.38          122.80     1001.0   \n",
      "1      842517         M        20.57         17.77          132.90     1326.0   \n",
      "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3    84348301         M        11.42         20.38           77.58      386.1   \n",
      "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
      "..        ...       ...          ...           ...             ...        ...   \n",
      "564    926424         M        21.56         22.39          142.00     1479.0   \n",
      "565    926682         M        20.13         28.25          131.20     1261.0   \n",
      "566    926954         M        16.60         28.08          108.30      858.1   \n",
      "567    927241         M        20.60         29.33          140.10     1265.0   \n",
      "568     92751         B         7.76         24.54           47.92      181.0   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0            0.11840           0.27760         0.30010              0.14710   \n",
      "1            0.08474           0.07864         0.08690              0.07017   \n",
      "2            0.10960           0.15990         0.19740              0.12790   \n",
      "3            0.14250           0.28390         0.24140              0.10520   \n",
      "4            0.10030           0.13280         0.19800              0.10430   \n",
      "..               ...               ...             ...                  ...   \n",
      "564          0.11100           0.11590         0.24390              0.13890   \n",
      "565          0.09780           0.10340         0.14400              0.09791   \n",
      "566          0.08455           0.10230         0.09251              0.05302   \n",
      "567          0.11780           0.27700         0.35140              0.15200   \n",
      "568          0.05263           0.04362         0.00000              0.00000   \n",
      "\n",
      "     ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0    ...          17.33           184.60      2019.0           0.16220   \n",
      "1    ...          23.41           158.80      1956.0           0.12380   \n",
      "2    ...          25.53           152.50      1709.0           0.14440   \n",
      "3    ...          26.50            98.87       567.7           0.20980   \n",
      "4    ...          16.67           152.20      1575.0           0.13740   \n",
      "..   ...            ...              ...         ...               ...   \n",
      "564  ...          26.40           166.10      2027.0           0.14100   \n",
      "565  ...          38.25           155.00      1731.0           0.11660   \n",
      "566  ...          34.12           126.70      1124.0           0.11390   \n",
      "567  ...          39.42           184.60      1821.0           0.16500   \n",
      "568  ...          30.37            59.16       268.6           0.08996   \n",
      "\n",
      "     compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0              0.66560           0.7119                0.2654          0.4601   \n",
      "1              0.18660           0.2416                0.1860          0.2750   \n",
      "2              0.42450           0.4504                0.2430          0.3613   \n",
      "3              0.86630           0.6869                0.2575          0.6638   \n",
      "4              0.20500           0.4000                0.1625          0.2364   \n",
      "..                 ...              ...                   ...             ...   \n",
      "564            0.21130           0.4107                0.2216          0.2060   \n",
      "565            0.19220           0.3215                0.1628          0.2572   \n",
      "566            0.30940           0.3403                0.1418          0.2218   \n",
      "567            0.86810           0.9387                0.2650          0.4087   \n",
      "568            0.06444           0.0000                0.0000          0.2871   \n",
      "\n",
      "     fractal_dimension_worst  Unnamed: 32  \n",
      "0                    0.11890          NaN  \n",
      "1                    0.08902          NaN  \n",
      "2                    0.08758          NaN  \n",
      "3                    0.17300          NaN  \n",
      "4                    0.07678          NaN  \n",
      "..                       ...          ...  \n",
      "564                  0.07115          NaN  \n",
      "565                  0.06637          NaN  \n",
      "566                  0.07820          NaN  \n",
      "567                  0.12400          NaN  \n",
      "568                  0.07039          NaN  \n",
      "\n",
      "[569 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Breast_Cancer_data.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03994a4c-451f-43d0-85cb-8ec77bf2c562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('breast_cancer_data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# df = df.drop(' Unnamed: 32  ', axis=1) \n",
    "# print(\"\\nDataFrame after removing 'A':\")\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd1dce4-9d22-47e7-86b5-70a16c2fca71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values or fill them (here we drop for simplicity)\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "798caedd-e462-442d-8334-afd0bea75106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "First few rows of the dataset:\n",
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "Shape of the dataset: (569, 33)\n",
      "Checking for missing values:\n",
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n",
      "Shape of imputed data: (569, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of imputed data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, imputed_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Assign the imputed data back to the dataframe\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m data\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m=\u001b[39m imputed_data\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Ensure data is not empty after handling missing values\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of the dataset after handling missing values:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:885\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    884\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 885\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1893\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1892\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1894\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1933\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_frame_value(indexer, value, name)\n\u001b[0;32m   1930\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1931\u001b[0m     \u001b[38;5;66;03m# TODO: avoid np.ndim call in case it isn't an ndarray, since\u001b[39;00m\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;66;03m#  that will construct an ndarray, which will be wasteful\u001b[39;00m\n\u001b[1;32m-> 1933\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_2d_value(indexer, value)\n\u001b[0;32m   1935\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m lplane_indexer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(pi):\n\u001b[0;32m   1936\u001b[0m     \u001b[38;5;66;03m# We are setting multiple rows in a single column.\u001b[39;00m\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_column(ilocs[\u001b[38;5;241m0\u001b[39m], value, pi)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\indexing.py:1999\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_2d_value\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1997\u001b[0m     value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ilocs) \u001b[38;5;241m!=\u001b[39m value\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 1999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2000\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust have equal len keys and value when setting with an ndarray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2001\u001b[0m     )\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, loc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ilocs):\n\u001b[0;32m   2004\u001b[0m     value_col \u001b[38;5;241m=\u001b[39m value[:, i]\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an ndarray"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Breast_Cancer_data.csv'  # Replace with the actual file path\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "    raise\n",
    "\n",
    "# Check if the dataset is loaded correctly\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Print the shape of the dataset\n",
    "print(\"Shape of the dataset:\", data.shape)\n",
    "\n",
    "# Data preprocessing\n",
    "# Check for missing values\n",
    "print(\"Checking for missing values:\")\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Handle missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputed_data = imputer.fit_transform(data.iloc[:, 2:])\n",
    "\n",
    "# Ensure the imputed data has the correct shape\n",
    "print(\"Shape of imputed data:\", imputed_data.shape)\n",
    "\n",
    "# Assign the imputed data back to the dataframe\n",
    "data.iloc[:, 2:] = imputed_data\n",
    "\n",
    "# Ensure data is not empty after handling missing values\n",
    "print(\"Shape of the dataset after handling missing values:\", data.shape)\n",
    "if data.empty:\n",
    "    raise ValueError(\"Dataset is empty after handling missing values. Please check the data.\")\n",
    "\n",
    "# Encode diagnosis column (Malignant=1, Benign=0)\n",
    "print(\"Encoding diagnosis column:\")\n",
    "data['diagnosis'] = data['diagnosis'].apply(lambda x: 1 if x == 'M' else 0)\n",
    "print(data['diagnosis'].value_counts())\n",
    "\n",
    "# Define features and labels\n",
    "print(\"Defining features and labels:\")\n",
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "y = data['diagnosis']\n",
    "\n",
    "# Check if the dataset is not empty after preprocessing\n",
    "print(\"Shape of feature matrix X:\", X.shape)\n",
    "print(\"Shape of labels y:\", y.shape)\n",
    "if X.empty or y.empty:\n",
    "    raise ValueError(\"Dataset is empty after preprocessing. Please check the data.\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "print(\"Splitting the dataset into training and testing sets:\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set size: {len(X_train)}, Testing set size: {len(X_test)}\")\n",
    "\n",
    "# Standardize the features\n",
    "print(\"Standardizing the features:\")\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Implement the k-NN algorithm\n",
    "k = 5  # Initial choice for k\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Model evaluation\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "# Test the model with new data\n",
    "new_data = np.array([[17.99, 10.38, 122.8, 1001, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399, 0.04904, 0.05373, 0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6, 2019, 0.1622, 0.6656, 0.7119, 0.2654, 0.4601, 0.1189]])\n",
    "new_data = scaler.transform(new_data)\n",
    "new_prediction = knn.predict(new_data)\n",
    "print('New data prediction:', 'Malignant' if new_prediction[0] == 1 else 'Benign')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220bc87-bb6b-4757-9819-f7eaf8419feb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
